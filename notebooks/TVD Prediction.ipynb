{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUC Datathon 2020\n",
    "## Predicting Total Vertical Depth\n",
    "\n",
    "In this section of the competition we are tasked with building regression machine learning (or other)\n",
    "model that will be able to predict TVD (True Vertical Depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import general libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# import prediction libraries\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "# for polynomial feature extraction\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import well header data\n",
    "well_header = pd.read_csv(\"../data/WellHeader_Datathon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_header.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "well_header.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a random sample with selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_header[['EPAssetsId','TVD','TotalDepth','BH_Location','Formation','Field','Pool','WellProfile']].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total counts for some of the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Viking      5208\nMontney     3395\nCardium     1147\nDuvernay     687\nName: Formation, dtype: int64"
     },
     "metadata": {},
     "execution_count": 224
    }
   ],
   "source": [
    "well_header.Formation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_header.Pool.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_header.Field.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 6 vertical wells and one is missing the TVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_header.WellProfile.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_header[well_header['WellProfile']=='Vertical'][['EPAssetsId','TVD','TotalDepth']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove na's\n",
    "well_header_clean = well_header[['EPAssetsId','TVD','TotalDepth','Formation','BH_Location','Field','WellProfile']].dropna()\n",
    "# remove vertical wells\n",
    "well_header_clean = well_header_clean[well_header_clean.WellProfile != \"Vertical\"]\n",
    "well_header_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.lmplot( x=\"TotalDepth\", y=\"TVD\", data=well_header_clean, fit_reg=True, height= 5, legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.lmplot( x=\"TotalDepth\", y=\"TVD\", data=well_header_clean, \n",
    "            fit_reg=True,hue='Formation',legend=False,col=\"Formation\",col_wrap=2, height=5,order=3,\n",
    "            scatter_kws={'alpha':0.5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.lmplot( x=\"TotalDepth\", y=\"TVD\", data=well_header_clean, \n",
    "            fit_reg=False,hue='Field',legend=False,col=\"Formation\",col_wrap=2, height=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of TVD for horizontal vs directional wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_header[well_header['WellProfile']==\"Horizontal\"].TVD.plot(kind='hist',bins=40,color=\"blue\",alpha=0.5,figsize=(10, 7))\n",
    "well_header[well_header['WellProfile']==\"Directional\"].TVD.plot(kind='hist',bins=40,color=\"magenta\",alpha=0.5,figsize=(10, 7))\n",
    "plt.legend(labels=['Horizontal', 'Directional'])\n",
    "plt.title('Distribution of TVD', size=24)\n",
    "plt.xlabel('TVD', size=18)\n",
    "plt.ylabel('Frequency', size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore different prediction models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the Columns You Want to Use as Features and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['TotalDepth',\n",
    "            'Formation']\n",
    "target = ['TVD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Features and Target ('TVD') Values into Separate Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = well_header_clean[features]\n",
    "# X = pd.get_dummies(X,drop_first=False)\n",
    "y = well_header_clean[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      TotalDepth Formation\n7056      2188.0    Viking\n5917      1556.0    Viking\n2255      2284.0    Viking\n4181      1599.0    Viking\n1240      4348.0   Cardium\n5472      2026.0    Viking\n3478      5724.0  Duvernay\n4737      1485.0    Viking\n3151      3696.0   Montney\n2477      4591.0   Montney",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TotalDepth</th>\n      <th>Formation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7056</th>\n      <td>2188.0</td>\n      <td>Viking</td>\n    </tr>\n    <tr>\n      <th>5917</th>\n      <td>1556.0</td>\n      <td>Viking</td>\n    </tr>\n    <tr>\n      <th>2255</th>\n      <td>2284.0</td>\n      <td>Viking</td>\n    </tr>\n    <tr>\n      <th>4181</th>\n      <td>1599.0</td>\n      <td>Viking</td>\n    </tr>\n    <tr>\n      <th>1240</th>\n      <td>4348.0</td>\n      <td>Cardium</td>\n    </tr>\n    <tr>\n      <th>5472</th>\n      <td>2026.0</td>\n      <td>Viking</td>\n    </tr>\n    <tr>\n      <th>3478</th>\n      <td>5724.0</td>\n      <td>Duvernay</td>\n    </tr>\n    <tr>\n      <th>4737</th>\n      <td>1485.0</td>\n      <td>Viking</td>\n    </tr>\n    <tr>\n      <th>3151</th>\n      <td>3696.0</td>\n      <td>Montney</td>\n    </tr>\n    <tr>\n      <th>2477</th>\n      <td>4591.0</td>\n      <td>Montney</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 267
    }
   ],
   "source": [
    "X.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# taken from : \n",
    "#  https://stackoverflow.com/questions/47664061/how-to-apply-polynomial-transformation-to-subset-of-features-in-scikitlearn?rq=1\n",
    "\n",
    "\n",
    "# estimators need to inherit from these classes to play nicely with others\n",
    "class ColumnExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_cols = X[self.columns]\n",
    "        return X_cols\n",
    "\n",
    "# Using pandas get dummies to make pipeline a bit simpler by\n",
    "# avoiding one-hot and label encoder.     \n",
    "# Build the pipeline from a FeatureUnion that processes \n",
    "# numerical and one-hot encoded separately.\n",
    "# FeatureUnion puts them back together when it's done.\n",
    "pipe2nvars = Pipeline([\n",
    "    ('features', FeatureUnion([('num', \n",
    "                                Pipeline([('extract', \n",
    "                                           ColumnExtractor(columns=['TotalDepth'])),\n",
    "                                          ('poly', \n",
    "                                           PolynomialFeatures())  ])),\n",
    "                               ('cat_var', \n",
    "                                ColumnExtractor(columns=['Formation_Montney','Formation_Duvernay',\n",
    "                                                         'Formation_Cardium','Formation_Viking']))])\n",
    "    )])    \n",
    "\n",
    "pipe2nvars.set_params(features__num__poly__degree=3)\n",
    "X = pipe2nvars.fit_transform(pd.get_dummies(X, drop_first=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=324)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Linear Regression: Fit a model to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LinearRegression()"
     },
     "metadata": {},
     "execution_count": 270
    }
   ],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "235.36469281662391\n"
    }
   ],
   "source": [
    "RMSE = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Ridge regression: Fit a new regression model to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Ridge(alpha=10)"
     },
     "metadata": {},
     "execution_count": 292
    }
   ],
   "source": [
    "ridge_regressor = Ridge(alpha=10)\n",
    "ridge_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[2728.34211247],\n       [1909.55007677],\n       [ 737.38681269],\n       ...,\n       [ 693.03761515],\n       [ 693.21077646],\n       [ 687.92745496]])"
     },
     "metadata": {},
     "execution_count": 293
    }
   ],
   "source": [
    "y_prediction = ridge_regressor.predict(X_test)\n",
    "y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "234.83362707049935\n"
    }
   ],
   "source": [
    "RMSE = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Decision Tree Regressor: Fit a new regression model to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = well_header_clean[features]\n",
    "X = pd.get_dummies(X,drop_first=False)\n",
    "y = well_header_clean[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DecisionTreeRegressor(max_depth=6)"
     },
     "metadata": {},
     "execution_count": 296
    }
   ],
   "source": [
    "tree_regressor = DecisionTreeRegressor(max_depth=6)\n",
    "tree_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2736.65611111, 2550.42465753,  761.24994483, ...,  715.33861862,\n        715.33861862,  683.90898649])"
     },
     "metadata": {},
     "execution_count": 297
    }
   ],
   "source": [
    "y_prediction = tree_regressor.predict(X_test)\n",
    "y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "208.6504335100166\n"
    }
   ],
   "source": [
    "RMSE = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitducdatathoncondada7c15a70114402eb173408762f3ee5c",
   "display_name": "Python 3.8.5 64-bit ('DUCdatathon': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}