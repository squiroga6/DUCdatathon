{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUC Datathon 2020\n",
    "## Predicting Total Vertical Depth\n",
    "\n",
    "In this section of the competition we are tasked with building regression machine learning (or other)\n",
    "model that will be able to predict TVD (True Vertical Depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import general libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# import prediction libraries\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "# for polynomial feature extraction\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import well header data\n",
    "well_header = pd.read_csv(\"../data/WellHeader_Datathon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_header.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "well_header.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a random sample with selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_header[['EPAssetsId','TVD','TotalDepth','BH_Location','Formation','Field','Pool','WellProfile']].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total counts for some of the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_header.Formation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_header.Pool.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_header.Field.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 6 vertical wells and one is missing the TVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_header.WellProfile.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_header[well_header['WellProfile']=='Vertical'][['EPAssetsId','TVD','TotalDepth']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove na's\n",
    "well_header_clean = well_header[['EPAssetsId','TVD','TotalDepth','Formation','BH_Location','Field','WellProfile']].dropna()\n",
    "# remove vertical wells\n",
    "well_header_clean = well_header_clean[well_header_clean.WellProfile != \"Vertical\"]\n",
    "well_header_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.lmplot( x=\"TotalDepth\", y=\"TVD\", data=well_header_clean, fit_reg=True, height= 5, legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.lmplot( x=\"TotalDepth\", y=\"TVD\", data=well_header_clean, \n",
    "            fit_reg=True,hue='Formation',legend=False,col=\"Formation\",col_wrap=2, height=5,order=3,\n",
    "            scatter_kws={'alpha':0.5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.lmplot( x=\"TotalDepth\", y=\"TVD\", data=well_header_clean, \n",
    "            fit_reg=False,hue='Field',legend=False,col=\"Formation\",col_wrap=2, height=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of TVD for horizontal vs directional wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_header[well_header['WellProfile']==\"Horizontal\"].TVD.plot(kind='hist',bins=40,color=\"blue\",alpha=0.5,figsize=(10, 7))\n",
    "well_header[well_header['WellProfile']==\"Directional\"].TVD.plot(kind='hist',bins=40,color=\"magenta\",alpha=0.5,figsize=(10, 7))\n",
    "plt.legend(labels=['Horizontal', 'Directional'])\n",
    "plt.title('Distribution of TVD', size=24)\n",
    "plt.xlabel('TVD', size=18)\n",
    "plt.ylabel('Frequency', size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore different prediction models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the Columns You Want to Use as Features and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['TotalDepth',\n",
    "            'Formation']\n",
    "target = ['TVD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Features and Target ('TVD') Values into Separate Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = well_header_clean[features]\n",
    "# X = pd.get_dummies(X,drop_first=False)\n",
    "y = well_header_clean[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# taken from : \n",
    "#  https://stackoverflow.com/questions/47664061/how-to-apply-polynomial-transformation-to-subset-of-features-in-scikitlearn?rq=1\n",
    "\n",
    "\n",
    "# estimators need to inherit from these classes to play nicely with others\n",
    "class ColumnExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_cols = X[self.columns]\n",
    "        return X_cols\n",
    "\n",
    "# Using pandas get dummies to make pipeline a bit simpler by\n",
    "# avoiding one-hot and label encoder.     \n",
    "# Build the pipeline from a FeatureUnion that processes \n",
    "# numerical and one-hot encoded separately.\n",
    "# FeatureUnion puts them back together when it's done.\n",
    "pipe2nvars = Pipeline([\n",
    "    ('features', FeatureUnion([('num', \n",
    "                                Pipeline([('extract', \n",
    "                                           ColumnExtractor(columns=['TotalDepth'])),\n",
    "                                          ('poly', \n",
    "                                           PolynomialFeatures())  ])),\n",
    "                               ('cat_var', \n",
    "                                ColumnExtractor(columns=['Formation_Montney','Formation_Duvernay',\n",
    "                                                         'Formation_Cardium','Formation_Viking']))])\n",
    "    )])    \n",
    "\n",
    "pipe2nvars.set_params(features__num__poly__degree=3)\n",
    "X = pipe2nvars.fit_transform(pd.get_dummies(X, drop_first=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=324)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Linear Regression: Fit a model to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RMSE = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Ridge regression: Fit a new regression model to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_regressor = Ridge(alpha=10)\n",
    "ridge_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = ridge_regressor.predict(X_test)\n",
    "y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RMSE = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Decision Tree Regressor: Fit a new regression model to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = well_header_clean[features]\n",
    "X = pd.get_dummies(X,drop_first=False)\n",
    "y = well_header_clean[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_regressor = DecisionTreeRegressor(max_depth=6)\n",
    "tree_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = tree_regressor.predict(X_test)\n",
    "y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RMSE = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597158741000",
   "display_name": "Python 3.8.5 64-bit ('duc_datathon': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}